{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport os\nimport sys \nfrom warnings import filterwarnings as filt\n\nfilt('ignore')\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.style.use('dark_background')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-29T18:11:02.136093Z","iopub.execute_input":"2022-05-29T18:11:02.136323Z","iopub.status.idle":"2022-05-29T18:11:02.141587Z","shell.execute_reply.started":"2022-05-29T18:11:02.136302Z","shell.execute_reply":"2022-05-29T18:11:02.140812Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"base_path   = \"../input/lfwdatasetsupdated/\"\nimages_path = os.path.join(base_path, \"face_images\", \"lfw-dataset\", 'lfw-deepfunneled', 'lfw-deepfunneled')\npairs_path  = os.path.join(base_path, \"updated_pairs.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.142924Z","iopub.execute_input":"2022-05-29T18:11:02.143445Z","iopub.status.idle":"2022-05-29T18:11:02.150116Z","shell.execute_reply.started":"2022-05-29T18:11:02.143400Z","shell.execute_reply":"2022-05-29T18:11:02.149340Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(pairs_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.154180Z","iopub.execute_input":"2022-05-29T18:11:02.154529Z","iopub.status.idle":"2022-05-29T18:11:02.648179Z","shell.execute_reply.started":"2022-05-29T18:11:02.154502Z","shell.execute_reply":"2022-05-29T18:11:02.647429Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.649498Z","iopub.execute_input":"2022-05-29T18:11:02.649859Z","iopub.status.idle":"2022-05-29T18:11:02.655508Z","shell.execute_reply.started":"2022-05-29T18:11:02.649824Z","shell.execute_reply":"2022-05-29T18:11:02.654640Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.drop_duplicates().shape","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.657019Z","iopub.execute_input":"2022-05-29T18:11:02.657787Z","iopub.status.idle":"2022-05-29T18:11:02.964610Z","shell.execute_reply.started":"2022-05-29T18:11:02.657745Z","shell.execute_reply":"2022-05-29T18:11:02.963783Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport albumentations as A\nimport torch\nimport cv2 as cv","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.966063Z","iopub.execute_input":"2022-05-29T18:11:02.966603Z","iopub.status.idle":"2022-05-29T18:11:02.971315Z","shell.execute_reply.started":"2022-05-29T18:11:02.966548Z","shell.execute_reply":"2022-05-29T18:11:02.970538Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def read_img(base_path, img_name):\n    path = os.path.join(base_path, img_name)\n    img  = plt.imread(path)\n    return img\n\n\ndef load_model(mname):\n    base_path = '../input/face-detection-model'\n    mpath = os.path.join(base_path, mname)\n    device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n    return torch.hub.load('ultralytics/yolov5', 'custom', mpath, device = device)\n\ndef alb_transform(xs):\n    transform = A.Compose([\n        A.HorizontalFlip(0.5),\n        A.Rotate(limit = 35, border_mode = cv.BORDER_CONSTANT),\n        A.GaussianBlur(blur_limit = (3, 3)),\n        A.CoarseDropout(10)\n    ])\n    \n    tx = transform(image = xs)['image']\n    return tx\n\ndef alb_transform_batch(xs):\n    transform = A.Compose([\n        A.HorizontalFlip(0.5),\n        A.Rotate(limit = 35, border_mode = cv.BORDER_CONSTANT),\n        A.GaussianBlur(blur_limit = (3, 3)),\n        A.CoarseDropout(10)\n    ])\n    \n    transformed_imgs = []\n    for x in xs:\n        tx = transform(image = x)['image']\n        transformed_imgs.append(tx)\n    imgs = np.array(transformed_imgs)\n    return imgs\n\nclass GenerateIdx:\n    def __init__(self, n, test_size, seed):\n        np.random.seed(seed)\n        idx = [i for i in range(n)]\n        train_size = int(n - (n * test_size))\n        self.train_idx = np.random.choice(idx, train_size, replace = False).tolist()\n        self.test_idx  = [i for i in idx if i not in self.train_idx]\n        \ndef add_zeros(x, units = '000'):\n    return f'{units}{x}'[-4:]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.972674Z","iopub.execute_input":"2022-05-29T18:11:02.973289Z","iopub.status.idle":"2022-05-29T18:11:02.987281Z","shell.execute_reply.started":"2022-05-29T18:11:02.973252Z","shell.execute_reply":"2022-05-29T18:11:02.986598Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class ImgDataset:\n    def __init__(self, df, img_path, batch = 16, img_size = (64, 64), transform = True, subset = 'train', \n                 test_size = 0.2, seed = 0, shuffle = True, sanity_check = False):\n        self.data = df.copy()\n        if shuffle:\n            self.data = self.data.sample(frac = 1.0).reset_index(drop = True)\n        idx = GenerateIdx(self.data.shape[0], test_size, seed)\n        if subset == 'train':\n            self.data = self.data.iloc[idx.train_idx, :]\n        elif subset == 'validation':\n            self.data = self.data.iloc[idx.test_idx, :]\n            \n        if sanity_check:\n            self.data = self.data.head()\n            \n        self.img_path = img_path \n        self.batch = batch\n        self.transform = transform \n        self.img_size = img_size\n            \n    def load_dataset(self):\n        images1 = []\n        images2 = []\n        targets = []\n        \n        for _, rdf in self.data.iterrows():\n            img1, img2 = self.get_image_path(rdf, self.img_path)\n            match = rdf['match']\n            image1 = self.read_preprocess(img1)\n            image2 = self.read_preprocess(img2)\n            images1.append(image1)\n            images2.append(image2)\n            targets.append(float(match))\n        \n        print(f'Length of anchor images       : {len(images1)}')\n        print(f'Length of verification images : {len(images2)}')\n        print(f'Length of targets images      : {len(targets)}')\n            \n        images1 = tf.data.Dataset.from_tensor_slices(images1).batch(self.batch)\n        images2 = tf.data.Dataset.from_tensor_slices(images2).batch(self.batch)\n        targets = tf.data.Dataset.from_tensor_slices(targets).batch(self.batch)\n        \n        if self.transform:\n            images1 = (images1\n                        .map(self.tf_augment)\n#                         .map(self.tf_crop_imgs)\n                        .map(self.normalize)\n                      )\n            images2 = (images2\n                        .map(self.tf_augment)\n#                         .map(self.tf_crop_imgs)\n                        .map(self.normalize)\n                      )\n            \n        return images1, images2, targets\n    \n    def load_dataset_V2(self):\n        images1 = self.data[['name1', 'imgnum1']].values\n        images2 = self.data[['name2', 'imgnum2']].values\n        targets = self.data['match'].astype(float).values\n        \n        print(f'Length of anchor images       : {images1.shape[0]}')\n        print(f'Length of verification images : {images2.shape[0]}')\n        print(f'Length of targets images      : {targets.shape[0]}')\n        \n        images1 = tf.data.Dataset.from_tensor_slices(images1)\n        images2 = tf.data.Dataset.from_tensor_slices(images2)\n        targets = tf.data.Dataset.from_tensor_slices(targets).cache().batch(self.batch)\n        \n        if self.transform:\n            images1 = (images1\n                        .map(self.tf_read_img)\n                        .map(self.tf_augment)\n                        .map(self.normalize).cache().batch(self.batch)\n                      )\n            images2 = (images2\n                        .map(self.tf_read_img)\n                        .map(self.tf_augment)\n                        .map(self.normalize).cache().batch(self.batch)\n                      )\n        else:\n            images1 = (images1\n                        .map(self.tf_read_img)\n                        .map(self.normalize).cache().batch(self.batch)\n                      )\n            images2 = (images2\n                        .map(self.tf_read_img)\n                        .map(self.normalize).cache().batch(self.batch)\n                      )\n            \n        return images1, images2, targets\n            \n    def read_preprocess(self, img):\n        image = plt.imread(img)\n        image = cv.resize(image, self.img_size)\n        channel = image.shape[-1]\n        if channel == 1:\n            image = cv.cvtColor(image, cv.COLOR_GRAY2RGB)\n        elif channel == 4:\n            image = cv.cvtColor(image, cv.COLOR_RGBA2RGB)\n            \n        return image\n    \n    def read_images(self, data):\n        name, num = data\n        path  = self.join_paths(self.img_path, name.decode('utf-8'), num.decode('utf-8'))\n        image = self.read_preprocess(path)\n        return image\n    \n    def read_images_batches(self, data):\n        images = []\n        for d in data:\n            image = self.read_images(d)\n            images.append(image)\n        images = np.array(images)\n        return images\n    \n    def tf_read_img(self, data):\n        images = tf.numpy_function(func = self.read_images, inp = [data], Tout = tf.uint8)\n        return images\n    \n    def tf_augment(self, image):\n        aug_img = tf.numpy_function(func = self.transform, inp = [image], Tout = tf.uint8)\n        return aug_img\n    \n    def tf_crop_imgs(self, image):\n        crop_img = tf.numpy_function(func = self.crop_faces, inp = [image], Tout = tf.uint8)\n        return crop_img\n        \n    def crop_faces(self, x):\n        x = [i for i in x]\n        pred = self.model(x).xyxy\n        imgs = []\n        \n        for i in range(len(x)):\n            p = pred[i][0]\n            img = x[i][int(p[1]) : int(p[3]), int(p[0]) : int(p[2])]\n            img = cv.resize(img, self.img_size)\n            imgs.append(img)\n        \n        imgs = np.array(imgs)\n        return imgs\n            \n    def __len__(self):\n        return self.data.shape[0]\n    \n    @staticmethod\n    def get_image_path(rdf, base_path):\n        name1 = rdf['name1']\n        name2 = rdf['name2']\n        num1  = str(rdf['imgnum1'])\n        num2  = str(rdf['imgnum2'])\n        \n        return (\n                  self.join_paths(base_path, name1, num1),\n                  self.join_pathsths(base_path, name2, num2)\n                )\n    \n    @staticmethod\n    def join_paths(base_path, name, num):\n        return os.path.join(base_path, name, f\"{name}_{add_zeros(num)}.jpg\")\n    \n    @staticmethod\n    def normalize(x):\n        img = x / 255\n        return img\n    \n    \nfrom sklearn.model_selection import train_test_split\ndef sample_split(df, y, frac = 0.2, save_idx = False, delim = ', '):\n    xcol = [c for c in df.columns if c != y]\n    x = df[xcol]\n    y = df[y]\n    x, xt, y, yt = train_test_split(x, y, test_size = frac, stratify = y)\n\n    print(f'Split size  :==> {frac}')\n    print(f'Sample size :==> {xt.shape[0]}')\n    print()\n    \n    if save_idx:\n        filename = 'idx_batch.txt'\n        idx = delim.join(list(map(str, xt.index.values)))\n        with open(filename, 'w') as file:\n            file.write(idx)\n        \n        print(f'Saved the idx to filename : {filename}')\n    \n    ndf1 = pd.concat([xt, yt], axis = 1).sample(frac = 1.0)\n    ndf1.index = xt.index\n    ndf2 = pd.concat([x, y], axis = 1).sample(frac = 1.0)\n    ndf2.index = x.index\n    return ndf1, ndf2\n\ndef remove_prev_batch_df_from_file(df, filename = 'idx_batch.txt', delim = ', '):\n    with open(filename, 'r') as file:\n        idx = file.read()\n        \n    idx = list(map(int, idx.split(delim)))\n    idx = [i for i in df.index if i not in idx]\n    return df.iloc[idx, :]\n\ndef remove_prev_batch_df(df, idx = []):\n    idx = [i for i in df.index.values if i not in idx]\n    return df.iloc[idx, :]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:02.988541Z","iopub.execute_input":"2022-05-29T18:11:02.989033Z","iopub.status.idle":"2022-05-29T18:11:03.029087Z","shell.execute_reply.started":"2022-05-29T18:11:02.988999Z","shell.execute_reply":"2022-05-29T18:11:03.028372Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"(df.shape[0] * 0.105) * 8, df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:03.030300Z","iopub.execute_input":"2022-05-29T18:11:03.030703Z","iopub.status.idle":"2022-05-29T18:11:03.044111Z","shell.execute_reply.started":"2022-05-29T18:11:03.030670Z","shell.execute_reply":"2022-05-29T18:11:03.043401Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# df.shape[0] * (103193 / (df.shape[0] - df1.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:03.045369Z","iopub.execute_input":"2022-05-29T18:11:03.046162Z","iopub.status.idle":"2022-05-29T18:11:03.051404Z","shell.execute_reply.started":"2022-05-29T18:11:03.046127Z","shell.execute_reply":"2022-05-29T18:11:03.050587Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df.shape[0] * 0.11731849926727808","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:03.052552Z","iopub.execute_input":"2022-05-29T18:11:03.053275Z","iopub.status.idle":"2022-05-29T18:11:03.061245Z","shell.execute_reply.started":"2022-05-29T18:11:03.053236Z","shell.execute_reply":"2022-05-29T18:11:03.060201Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# training batches \nsplit_frac = 0.105\nndf = df.copy()\ndf1, ndf = sample_split(ndf, 'match', split_frac)\ndf1[['imgnum1', 'imgnum2', 'match']] = df1[['imgnum1', 'imgnum2', 'match']].astype(str) \ntraining_batches_dfs = [df1]\n\nfor i in range(7):\n    n = df1.shape[0]\n    d = df.shape[0]\n    for bdf in training_batches_dfs:\n        d -= bdf.shape[0]\n    split_frac = n / d\n    dfn, ndf = sample_split(ndf, 'match', split_frac)\n    dfn[['imgnum1', 'imgnum2', 'match']] = dfn[['imgnum1', 'imgnum2', 'match']].astype(str)\n    training_batches_dfs.append(dfn)\n    \nvalidation_df, test_df = sample_split(ndf, 'match', 0.5)\nvalidation_df[['imgnum1', 'imgnum2', 'match']] = validation_df[['imgnum1', 'imgnum2', 'match']].astype(str)\ntest_df[['imgnum1', 'imgnum2', 'match']] = test_df[['imgnum1', 'imgnum2', 'match']].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:03.062783Z","iopub.execute_input":"2022-05-29T18:11:03.063188Z","iopub.status.idle":"2022-05-29T18:11:08.756572Z","shell.execute_reply.started":"2022-05-29T18:11:03.063134Z","shell.execute_reply":"2022-05-29T18:11:08.755731Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.figure(1, figsize = (20, 15))\nplt.tight_layout()\nfor i in range(len(training_batches_dfs)):\n    plt.subplot(2, 4, i + 1)\n    sns.countplot(training_batches_dfs[i]['match'])\n    plt.title(f'Training Batch : {i + 1}')","metadata":{"execution":{"iopub.status.busy":"2022-05-29T17:09:36.534691Z","iopub.execute_input":"2022-05-29T17:09:36.535090Z","iopub.status.idle":"2022-05-29T17:09:38.080528Z","shell.execute_reply.started":"2022-05-29T17:09:36.535051Z","shell.execute_reply":"2022-05-29T17:09:38.079743Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate_train_data_generator(training_batches_dfs, SIZE, batch):\n    for ind, bdf in enumerate(training_batches_dfs):\n        print(f'Processing training batch : {ind + 1}')\n        train_data = ImgDataset(bdf, images_path, batch, img_size = (SIZE, SIZE), test_size = 0.0, \n                                seed = 123, transform = alb_transform) \n        train_data = train_data.load_dataset_V2()\n        train_data = tf.data.Dataset.zip(train_data).prefetch(1)\n        yield train_data","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:08.757995Z","iopub.execute_input":"2022-05-29T18:11:08.758341Z","iopub.status.idle":"2022-05-29T18:11:08.764681Z","shell.execute_reply.started":"2022-05-29T18:11:08.758304Z","shell.execute_reply":"2022-05-29T18:11:08.763737Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# training data \nSIZE = 64 * 2\nbatch = 16\ntf_train_data = generate_train_data_generator(training_batches_dfs, SIZE, batch)\n\n# # validation data\n# val_data = ImgDataset(validation_df, images_path, batch, img_size = (SIZE, SIZE), test_size = 0.0, \n#                       seed = 123, transform = None) \n# val_data = val_data.load_dataset_V2()\n# val_data = tf.data.Dataset.zip(val_data).prefetch(tf.data.AUTOTUNE)\n\n# # testing data  \n# test_data = ImgDataset(test_df, images_path, batch, img_size = (SIZE, SIZE), test_size = 0.0, \n#                       seed = 123, transform = None) \n# test_data = test_data.load_dataset_V2()\n# test_data = tf.data.Dataset.zip(test_data).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:08.766145Z","iopub.execute_input":"2022-05-29T18:11:08.766589Z","iopub.status.idle":"2022-05-29T18:11:08.780772Z","shell.execute_reply.started":"2022-05-29T18:11:08.766542Z","shell.execute_reply":"2022-05-29T18:11:08.780112Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_row(num, col):\n    if num % col == 0:\n        return num // col\n    return (num // col) + 1\n\ndef plot_tf_image(data, num, col = 4):\n    row = get_row(num, col)\n    \n    plt.figure(figsize = (col * 4, row * 4))\n    print('Anchor images'.center(60, '='))\n    print()\n    #anchor images\n    for td in train_data:\n        matches = td[2]\n        break_it = False\n        for i, img in enumerate(td[0]):\n            plt.subplot(row, col, i + 1)\n            plt.imshow(img)\n            plt.title(f\"{'same person' if matches[i] == 1 else 'not a same person'}\")\n            plt.axis(False)\n            if i + 1 >= num:\n                break_it = True\n                break\n        if break_it:\n            break\n        \n    plt.show()\n        \n    plt.figure(figsize = (col * 4, row * 4))\n    print('Verification images'.center(60, '='))\n    print()\n    #verification images\n    for td in train_data:\n        matches = td[2]\n        break_it = False\n        for i, img in enumerate(td[1]):\n            plt.subplot(row, col, i + 1)\n            plt.imshow(img)\n            plt.title(f\"{'same person' if matches[i] == 1 else 'not a same person'}\")\n            plt.axis(False)\n            if i + 1 >= num:\n                break_it = True\n                break\n        if break_it:\n            break\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:08.782135Z","iopub.execute_input":"2022-05-29T18:11:08.782552Z","iopub.status.idle":"2022-05-29T18:11:08.797314Z","shell.execute_reply.started":"2022-05-29T18:11:08.782492Z","shell.execute_reply":"2022-05-29T18:11:08.796539Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"plot_tf_image(tf_train_data[0], 8, 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Layer, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras import backend as k\n\nclass Distance(Layer):\n    def __init__(self, **kwargs):\n        super().__init__()\n        \n    def euclidean_dist(self, vectors):\n        vec1, vec2 = vectors\n        dist = k.sum(k.square(vec1 - vec2), axis = 1, keepdims = True)\n        return k.sqrt(k.maximum(dist, k.epsilon()))\n    \n    def call(self, anchor, verification):\n        return self.euclidean_dist([anchor, verification])\n\nclass SimeaseNet:\n    def __init__(self, encoding_model, training = True):\n        self.encoding_model = encoding_model\n        self.encoding_model._name = \"Encoder\"\n        self.training = training\n        \n    def encode(self, x):\n        feat = self.encoding_model(x)\n        return feat\n    \n    def enable_training_mode(self):\n        self.training = True\n        self.model.trainable = self.training\n        self.encoding_model.trainable = self.training\n        \n        print('Set the encoding and siamese model to training mode ...')\n        \n    def enable_inference_mode(self):\n        self.training = False\n        self.model.trainable = self.training\n        self.encoding_model.trainable = self.training\n        \n        print('Set the encoding and siamese model to inference mode ...')\n    \n    def build_model(self):\n        dist    = Distance()\n        dist._name = 'Distance'\n        \n        input1  = Input(shape = (SIZE, SIZE, 3), name = 'anchor')\n        input2  = Input(shape = (SIZE, SIZE, 3), name = 'verification')\n        feat1   = self.encode(input1)\n        feat2   = self.encode(input2)\n        d       = dist(feat1, feat2)\n        output  = Dense(1, activation = 'sigmoid', name = 'classifier')(d)\n        self.model   = Model(inputs = [input1, input2], outputs = output)\n        self.model._name = 'SiameseNet'\n        \n        if self.training:\n            self.enable_training_mode()\n        else:\n            self.enable_inference_mode()\n            \n        return self.model\n    \ndef base_model(ip, verbose = True):\n    model = DenseNet121(include_top = False, weights = 'imagenet', input_shape = ip)\n    for layer in model.layers:\n        layer.trainable = False\n    \n    x = GlobalAveragePooling2D()(model.output)\n    x = Dense(512, activation = 'relu')(x)\n    x = Dense(128)(x)\n    \n    model = Model(inputs = model.input, outputs = x)\n    if verbose:\n        print(model.summary())\n        \n    return model\n\ndef checkpoint(opt, model):\n    ckpt_base_path = \"./training_checkpoints\"\n    ckpt_path      = os.path.join(ckpt_base_path, 'ckpt')\n    ckpt           = tf.train.Checkpoint(opt = opt, siamese_model = model)\n    ckpt.save(file_prefix = ckpt_path)\n    \n    \n@tf.function\ndef train_on_batch(batch, model, opt, loss_func, verbose = True):\n    with tf.GradientTape() as tape: \n        X = batch[:2]\n        y = batch[2]\n        yhat = model(X, training = True)\n        loss = loss_func(y, yhat)\n    \n    del X, y, yhat\n    print(f'Loss : {loss}')\n    grad = tape.gradient(loss, model.trainable_variables)\n    opt.apply_gradients(zip(grad, model.trainable_variables))\n    \n    return loss\n\ndef train_model(data, model, opt, loss_func, epochs = 5, save_model = 0, verbose = True):\n    history = {\n        'loss' : [],\n        'accuracy' : []\n    }\n    for epoch in range(1, epochs + 1):\n        print(f'Epoch : {epoch} / {epochs} ', end = ' ')\n        progbar = tf.keras.utils.Progbar(len(data))\n        l = []\n        for idx, batch in enumerate(data):\n            loss = train_on_batch(batch, model, opt, loss_func, verbose = verbose)\n            progbar.update(idx + 1)\n            l.append(loss)\n            \n        if save_model > 0:\n            if epoch % save_model == 0:\n                checkpoint(opt, model)\n                \n        history['loss'].append(np.mean(l))\n        del l\n        \n    return model, opt, history","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:08.798321Z","iopub.execute_input":"2022-05-29T18:11:08.798813Z","iopub.status.idle":"2022-05-29T18:11:09.657628Z","shell.execute_reply.started":"2022-05-29T18:11:08.798775Z","shell.execute_reply":"2022-05-29T18:11:09.656729Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"ip = (SIZE, SIZE, 3)\nencoding_model = base_model(ip, verbose = False)\nmodel = SimeaseNet(encoding_model)\nmodel = model.build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:09.659117Z","iopub.execute_input":"2022-05-29T18:11:09.659535Z","iopub.status.idle":"2022-05-29T18:11:19.653978Z","shell.execute_reply.started":"2022-05-29T18:11:09.659495Z","shell.execute_reply":"2022-05-29T18:11:19.653167Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adagrad, Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nimport gc\n\nEPOCHS = 2\nfor train_data in tf_train_data:\n    gc.collect()\n    model, opt, his = train_model(train_data, model, Adam(learning_rate = 0.001), BinaryCrossentropy(), EPOCHS, 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:11:19.657003Z","iopub.execute_input":"2022-05-29T18:11:19.657275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(his):\n    loss, accu = his['loss'], his['accuracy']\n    plt.figure(1)\n    plt.plot(loss)\n    plt.plot(accu)\n    plt.title('Loss and Accuracy Over Epoch')\n    plt.legend(['loss', 'accuracy'])\n    \ndef plot_image(img):\n    plt.imshow(img)\n    plt.axis(False)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(his)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall\nfrom sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, roc_curve\n\ndef plot_metrics(history):\n    precision = Precision()(history['true'], history['pred']).numpy()\n    recall    = Recall()(history['true'], history['pred']).numpy()\n    f1score   = f1_score(history['true'], history['pred'])\n    conf_mat  = confusion_matrix(history['true'], history['pred'])\n    \n    print(' Metrics Report '.center(70, '='))\n    print()\n    print(f'Precision :==> {precision}')\n    print(f'Recall    :==> {recall}')\n    print(f'F1 score  :==> {f1score}')\n    print()\n    sns.heatmap(conf_mat, fmt = '.2f', annot = True, cmap = 'hotr')\n    plt.show()\n\n\ndef inference_model(model, val_data, thresh = 0.5, show_metrics = True):\n    history = {\n        'true'      : [],\n        'pred'      : [],\n    }\n    \n    for anchor, verification, y in val_data.as_numpy_iterator():\n        pred = (model.predict([anchor, verification]) >= thresh).astype(int)\n        history['true'] += y.tolist()\n        history['pred'] += pred.tolist()\n        \n    if show_metrics:\n        plot_metrics(history)\n        \n    return history\n\ndef plot_comparision(data):\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ihis = inference_model(model, val_data)","metadata":{},"execution_count":null,"outputs":[]}]}